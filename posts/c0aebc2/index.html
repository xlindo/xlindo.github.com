<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Math - Fisher Information - xlindo is here</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="xlindo is here"><meta name="msapplication-TileImage" content="/images/favicon.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="xlindo is here"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Fisher information matrix is very important in my master&amp;#39;s thesis paper, but it is complicated than I expected before. So this blog is about to illustrate what it is and how to calculate."><meta property="og:type" content="blog"><meta property="og:title" content="Math - Fisher Information"><meta property="og:url" content="https://xlindo.com/posts/c0aebc2/"><meta property="og:site_name" content="xlindo is here"><meta property="og:description" content="Fisher information matrix is very important in my master&amp;#39;s thesis paper, but it is complicated than I expected before. So this blog is about to illustrate what it is and how to calculate."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://xlindo.com/img/og_image.png"><meta property="article:published_time" content="2019-07-06T12:26:45.000Z"><meta property="article:modified_time" content="2023-05-08T22:07:53.999Z"><meta property="article:author" content="xlindo"><meta property="article:tag" content="inEnglish"><meta property="article:tag" content="数据分析"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://xlindo.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://xlindo.com/posts/c0aebc2/"},"headline":"Math - Fisher Information","image":["https://xlindo.com/img/og_image.png"],"datePublished":"2019-07-06T12:26:45.000Z","dateModified":"2023-05-08T22:07:53.999Z","author":{"@type":"Person","name":"xlindo"},"publisher":{"@type":"Organization","name":"xlindo is here","logo":{"@type":"ImageObject","url":"https://xlindo.com/images/favicon.ico"}},"description":"Fisher information matrix is very important in my master&#39;s thesis paper, but it is complicated than I expected before. So this blog is about to illustrate what it is and how to calculate."}</script><link rel="canonical" href="https://xlindo.com/posts/c0aebc2/"><link rel="icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><meta name="msvalidate.01" content="043B69617A5E44A2F7CD99A00708FFF3"><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/favicon.ico" alt="xlindo is here" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-06T12:26:45.000Z" title="7/6/2019, 8:26:45 PM">2019-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-05-08T22:07:53.999Z" title="5/9/2023, 6:07:53 AM">2023-05-09</time></span><span class="level-item"><a class="link-muted" href="/categories/%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%BB%9F%E8%AE%A1/">数学与统计</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Math - Fisher Information</h1><div class="content"><blockquote>
<p><a href="https://xlindo.com/">https://xlindo.com</a><br>所有文章遵循<a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>许可协议。请按许可使用。<br>Blog content follows the <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en">CC BY-NC-SA 4.0</a> License.</p>
</blockquote>
<p>Fisher information matrix is very important in my master’s thesis paper, but it is complicated than I expected before. So this blog is about to illustrate what it is and how to calculate. If time is adequate for me, I will give a Matlab example <code>todo</code>.</p>
<span id="more"></span>

<blockquote>
<p><a target="_blank" rel="noopener" href="https://web.stanford.edu/class/stats311/">chapter Fisher Information</a><br><a target="_blank" rel="noopener" href="https://wiseodd.github.io/techblog/2018/03/11/fisher-information/">Agustinus Kristiadi’s Blog</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1705.01064.pdf">A Tutorial on Fisher Information</a><br><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Fisher_information">wiki&#x2F;Fisher_information</a>  </p>
</blockquote>
<h1 id="0-Introduction"><a href="#0-Introduction" class="headerlink" title="0 Introduction"></a>0 Introduction</h1><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Fisher_information">Fisher information, From Wikipedia</a> says the Fisher information is a way of measuring the amount of information that an observable random variable X carries about an unknown parameter $\theta$ of a distribution that models $X$.</p>
<p>Formally, it is <strong>the variance of the score</strong>, or the <strong>expected value of the observed information</strong>. </p>
<p>In Bayesian statistics, the asymptotic distribution of the posterior mode depends on the Fisher information and not on the prior.</p>
<p>The role of the Fisher information in the asymptotic theory of <strong>maximum-likelihood estimation</strong> was emphasized by the statistician Ronald Fisher. </p>
<p>The Fisher information is also used in the calculation of the Jeffreys prior, which is used in Bayesian statistics.</p>
<h1 id="1-Fisher-information"><a href="#1-Fisher-information" class="headerlink" title="1 Fisher information"></a>1 Fisher information</h1><h2 id="1-1-Basic-ideas"><a href="#1-1-Basic-ideas" class="headerlink" title="1.1 Basic ideas"></a>1.1 Basic ideas</h2><blockquote>
<p>Suppose you already know the <em>Maximum Likelihood Estimation</em>.</p>
</blockquote>
<p>Let $f(X; \theta)$ be the probability density function (or probability mass function) for $X$ conditional on the value of $\theta$. This is also the likelihood function for $\theta$. In practice, the true value of $\theta$ is not known and has to be inferred from the observed data. </p>
<p>If $f$ is sharply peaked wrt. changes in $\theta$, it is easy to indicate the “correct” value of $\theta$ from the data, or equivalently, that the data X provides a lot of information about the parameter $\theta$, which means not much samples need to be used.</p>
<h2 id="1-2-Score"><a href="#1-2-Score" class="headerlink" title="1.2 Score"></a>1.2 Score</h2><blockquote>
<p>In statistics, the score (or informant) is the gradient of the log-likelihood function wrt. the parameter vector. Evaluated at a particular point, the score indicates the steepness of the log-likelihood function and thereby the sensitivity to infinitesimal changes to the parameter values. If the log-likelihood function is continuous over the parameter space, the score will vanish at a local maximum or minimum; this fact is used in <strong>maximum likelihood estimation</strong> to find the parameter values that maximize the likelihood function.</p>
</blockquote>
<p>Formally, it is the partial derivative wrt. $\theta$ of the natural logarithm of the likelihood function,<br>$$s(\theta)&#x3D;\frac{\partial}{\partial \theta} \log f(X ; \theta),$$</p>
<p> Under certain regularity conditions, it can be shown that the <strong>expected value</strong> (the first moment) of the score is 0:</p>
<blockquote>
<ul>
<li>$\mathbb{E}(X)&#x3D;\int_{-\infty}^{\infty} x f(x) d x$   </li>
<li>Consistent convergence, then: $\frac{d}{d x} \int f(x, y) d y&#x3D;\int \frac{\partial f(x, y)}{\partial x} d y$, more roughly, theorem in physical problems.</li>
</ul>
</blockquote>
<p>$$\begin{aligned} \underset{f(X ; \theta)}{\mathbb{E}}[s(\theta)| \theta] &amp;&#x3D;\underset{f(X ; \theta)}{\mathbb{E}}\left[\frac{\partial}{\partial \theta} \log f(X ; \theta)| \theta\right] \ &amp;&#x3D;\int \frac{\partial}{\partial \theta} \log f(x ; \theta) f(x ; \theta) \mathrm{d} x \ &amp;&#x3D;\int \frac{\frac{\partial}{\partial \theta} f(x ; \theta)}{f(x ; \theta)} f(x ; \theta) d x \ &amp;&#x3D;\frac{\partial}{\partial \theta} \int f(x ; \theta) d x \ &amp;&#x3D;\frac{\partial}{\partial \theta} 1 \ &amp;&#x3D;0 \end{aligned}$$</p>
<h2 id="1-3-Covariance-of-score-Fisher-information"><a href="#1-3-Covariance-of-score-Fisher-information" class="headerlink" title="1.3 Covariance of score - Fisher information"></a>1.3 Covariance of score - <strong>Fisher information</strong></h2><p>We can define an uncertainty measure around the expected estimate. That is, we look at the covariance of score of our model, which is known as <em>Fisher information</em>.<br>$$\begin{aligned}\mathcal{I}(\theta) &amp;&#x3D;\underset{f(X ; \theta)}{\mathbb{E}}\left[(s(\theta)-0)(s(\theta)-0)^{\mathrm{T}}| \theta\right]\ &amp;&#x3D;\underset{f(X ; \theta)}{\mathbb{E}}\left[\left(\frac{\partial}{\partial \theta} \log f(X ; \theta)\right)^{2} | \theta\right]\ &amp;&#x3D;\int\left(\frac{\partial}{\partial \theta} \log f(x ; \theta)\right)^{2} f(x ; \theta) d x\end{aligned}$$</p>
<p>If $\log{f(x; \theta)}$ is twice differentiable with respect to $\theta$, and under certain regularity conditions,  then the Fisher information may also be written as<br>$$\mathcal{I}(\theta)&#x3D;-\mathrm{E}\left[\frac{\partial^{2}}{\partial \theta^{2}} \log f(X ; \theta) | \theta\right],$$</p>
<p>Besides, the likelihood function is complicated, so <em>Empirical Fisher</em> is defined as,<br>$$\mathcal{I}(\theta)&#x3D;\frac{1}{N} \sum_{i&#x3D;1}^{N} \nabla \log f\left(x_{i} | \theta\right) \nabla \log f\left(x_{i} | \theta\right)^{\mathrm{T}}.$$</p>
<h2 id="1-4-Fisher-and-Hessian"><a href="#1-4-Fisher-and-Hessian" class="headerlink" title="1.4 Fisher and Hessian"></a>1.4 Fisher and Hessian</h2><p>$$\mathcal{I}(\theta)&#x3D;-\underset{f(X ; \theta)}{\mathbb{E}}\left[\mathbf{H}_{\log f(X ; \theta)}\right]$$</p>
<p>where<br>$$\begin{aligned}\mathrm{H}<em>{\log f(X | \theta)}&amp;&#x3D;\mathrm{J}\left(\frac{\nabla f(X ; \theta)}{f(X ; \theta)}\right) \ &amp;&#x3D; \frac{\mathrm{H}</em>{f(X ; \theta)}}{f(X ; \theta)}-\left(\frac{\nabla f(X ; \theta)}{f(X ; \theta)}\right)\left(\frac{\nabla f(X ; \theta)}{f(X ; \theta)}\right)^{\mathrm{T}}\end{aligned}$$</p>
<h2 id="1-5-Results"><a href="#1-5-Results" class="headerlink" title="1.5 Results"></a>1.5 Results</h2><p>Thus, the Fisher information may be seen as the curvature of the support curve (the graph of the log-likelihood). Near the maximum likelihood estimate, low Fisher information therefore indicates that the maximum appears “blunt”, that is, the maximum is shallow and there are many nearby values with a similar log-likelihood. Conversely, high Fisher information indicates that the maximum is sharp.</p>
<p>One of the most exciting results of $\mathcal{I}(\theta)$ is that it has connection to KL-divergence (Kullback–Leibler divergence, also called relative entropy). This gives rise to natural gradient method.</p>
<h1 id="2-Fisher-information-matrix-FIM"><a href="#2-Fisher-information-matrix-FIM" class="headerlink" title="2 Fisher information matrix (FIM)"></a>2 Fisher information matrix (FIM)</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Fisher_information">https://en.wikipedia.org/wiki/Fisher_information</a></p>
</blockquote>
<h2 id="2-1-Definition"><a href="#2-1-Definition" class="headerlink" title="2.1 Definition"></a>2.1 Definition</h2><p>When there are $N$ parameters, so that $\theta$ is an $N \times 1$ vector $\theta &#x3D;{\begin{bmatrix}\theta _{1},\theta _{2},\dots ,\theta _{N}\end{bmatrix}}^{\mathrm {T} },$ then the Fisher information takes the form of an $N \times N$ <em><strong>Fisher information matrix</strong></em>,</p>
<p>$$[\mathcal{I}(\theta)]<em>{i, j}&#x3D;\underset{f(X ; \theta)}{\mathbb{E}}\left[\left(\frac{\partial}{\partial \theta</em>{i}} \log f(X ; \theta)\right)\left(\frac{\partial}{\partial \theta_{j}} \log f(X ; \theta)\right) | \theta\right].$$</p>
<p>The <em>FIM</em> is a $N \times N$ positive semidefinite matrix. If it is positive definite, then it defines a <em>Riemannian metric</em> on the $N$-dimensional parameter space (<em>Information geometry</em>). </p>
<p>Under certain regularity conditions, the Fisher information matrix may also be written as<br>$$[\mathcal{I}(\theta)]<em>{i, j}&#x3D;-\underset{f(X ; \theta)}{\mathbb{E}}\left[\frac{\partial^{2}}{\partial \theta</em>{i} \partial \theta_{j}} \log f(X ; \theta) | \theta\right].$$</p>
<h2 id="2-2-Some-results"><a href="#2-2-Some-results" class="headerlink" title="2.2 Some results"></a>2.2 Some results</h2><ul>
<li>It can be derived as the Hessian of the relative entropy.</li>
<li>It can be understood as a metric induced from the Euclidean metric, after appropriate change of variable.</li>
<li>In its complex-valued form, it is the Fubini–Study metric.<br>It is the key part of the proof of Wilks’ theorem, which allows confidence region estimates for maximum likelihood estimation (for those conditions for which it applies) without needing the Likelihood Principle.</li>
<li>In cases where the <strong>analytical calculations of the FIM above are difficult, it is possible to form an average of easy Monte Carlo estimates of the Hessian of the negative log-likelihood function as an estimate of the FIM.</strong>[6][7][8] The estimates may be based on values of the negative log-likelihood function or the gradient of the negative log-likelihood function; no analytical calculation of the Hessian of the negative log-likelihood function is needed.</li>
</ul>
<blockquote>
<p>[6] “Monte Carlo Computation of the Fisher Information Matrix in Nonstandard Settings” <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1198/106186005X78800">http://dx.doi.org/10.1198/106186005X78800</a><br>[7] “Improved Methods for Monte Carlo Estimation of the Fisher Information Matrix” <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1109/ACC.2008.4586850">http://dx.doi.org/10.1109/ACC.2008.4586850</a><br>[8] “Efficient Monte Carlo Computation of Fisher Information Matrix Using Prior Information” <a target="_blank" rel="noopener" href="http://dx.doi.org/10.1016/j.csda.2009.09.018">http://dx.doi.org/10.1016/j.csda.2009.09.018</a>  </p>
</blockquote>
<h2 id="2-3-Orthogonal-parameters"><a href="#2-3-Orthogonal-parameters" class="headerlink" title="2.3 Orthogonal parameters"></a>2.3 Orthogonal parameters</h2><p>When dealing with research problems, it is very common for the researcher to invest some time searching for an orthogonal parametrization of the densities involved in the problem.</p>
<h2 id="2-4-Singular-statistical-model"><a href="#2-4-Singular-statistical-model" class="headerlink" title="2.4 Singular statistical model"></a>2.4 Singular statistical model</h2><p>If the Fisher information matrix is positive definite for all $\theta$, then the corresponding statistical model is said to be regular; otherwise, the statistical model is said to be singular. Examples of singular statistical models include the following: normal mixtures, binomial mixtures, multinomial mixtures, Bayesian networks, neural networks, radial basis functions, hidden Markov models, stochastic context-free grammars, reduced rank regressions, Boltzmann machines.</p>
<p>In machine learning, if a statistical model is devised so that it extracts hidden structure from a random phenomenon, then it naturally becomes singular.</p>
<h2 id="2-5-Multivariate-normal-distribution"><a href="#2-5-Multivariate-normal-distribution" class="headerlink" title="2.5 Multivariate normal distribution"></a>2.5 Multivariate normal distribution</h2><p>The FIM for a N-variate multivariate normal distribution, $X\sim N\left(\mu (\theta ),\Sigma (\theta )\right)$ has a special form.</p>
<h1 id="3-Applications"><a href="#3-Applications" class="headerlink" title="3 Applications"></a>3 Applications</h1><h2 id="3-1-Optimal-design-of-experiments"><a href="#3-1-Optimal-design-of-experiments" class="headerlink" title="3.1 Optimal design of experiments"></a>3.1 <strong>Optimal design of experiments</strong></h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Optimal_design">&#x2F;wiki&#x2F;Optimal_design</a></p>
</blockquote>
<p>Because of the reciprocity of estimator-variance and Fisher information, minimizing the variance corresponds to maximizing the information.</p>
<p>The inverse of the variance of the estimated parameter is called the <em>information matrix</em>. It is complicated to minimizing the information matrix.</p>
<p>Traditionally, statisticians have evaluated estimators and designs by considering some <strong>summary statistic</strong> of the covariance matrix (of an unbiased estimator), usually with positive real values (like the determinant or matrix trace). </p>
<p>The traditional optimality criteria are the information matrix’s invariants, in the sense of invariant theory; algebraically, the traditional optimality criteria are functionals of the eigenvalues of the (Fisher) information matrix (see <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Optimal_design">optimal design</a>).</p>
<h2 id="3-2-Jeffreys-prior-in-Bayesian-statistics"><a href="#3-2-Jeffreys-prior-in-Bayesian-statistics" class="headerlink" title="3.2 Jeffreys prior in Bayesian statistics"></a>3.2 Jeffreys prior in Bayesian statistics</h2><p>In Bayesian statistics, the Fisher information is used to calculate the Jeffreys prior, which is a standard, non-informative prior for continuous distribution parameters.</p>
<h2 id="3-3-Computational-neuroscience"><a href="#3-3-Computational-neuroscience" class="headerlink" title="3.3 Computational neuroscience"></a>3.3 Computational neuroscience</h2><p>The Fisher information has been used to find bounds on the accuracy of neural codes. In that case, $X$ is typically the joint responses of many neurons representing a low dimensional variable $\theta$ (such as a stimulus parameter). In particular the role of correlations in the noise of the neural responses has been studied.</p>
<h2 id="3-4-Machine-learning"><a href="#3-4-Machine-learning" class="headerlink" title="3.4 Machine learning"></a>3.4 Machine learning</h2><p>The Fisher information is used in machine learning techniques such as elastic weight consolidation, which reduces catastrophic forgetting in artificial neural networks.</p>
<h2 id="3-5-Relation-to-relative-entropy"><a href="#3-5-Relation-to-relative-entropy" class="headerlink" title="3.5 Relation to relative entropy"></a>3.5 Relation to relative entropy</h2><p>If $\theta$  is fixed, then the relative entropy between two distributions of the same family is minimized at $\theta ‘&#x3D;\theta$. For $\theta ‘$ close to $\theta$, one may expand the previous expression in a series up to second order:</p>
<p>$$\begin{aligned}D\left(\theta | \theta^{\prime}\right)&amp;&#x3D;\int f(x ; \theta) \log \frac{f(x ; \theta)}{f\left(x ; \theta^{\prime}\right)} d x\&amp;&#x3D;\int f(x ; \theta)\left(\log f(x ; \theta)-\log f\left(x ; \theta^{\prime}\right)\right) d x \&amp;&#x3D;\frac{1}{2}\left(\theta^{\prime}-\theta\right)^{\top} \underbrace{\left(\frac{\partial^{2}}{\partial \theta_{i}^{\prime} \partial \theta_{j}^{\prime}} D\left(\theta | \theta^{\prime}\right)\right)<em>{\theta^{\prime}&#x3D;\theta}}</em>{\text { Fisher info. }}\left(\theta^{\prime}-\theta\right)+\cdots\end{aligned}$$</p>
<p><strong>Thus the Fisher information represents the curvature of the relative entropy.</strong></p>
<blockquote>
<p>Schervish (1995: §2.3) says the following.<br>One advantage Kullback-Leibler information has over <em>Fisher information</em> is that it is not affected by changes in parameterization. Another advantage is that Kullback-Leibler information can be used even if the distributions under consideration are not all members of a parametric family.<br>…<br>Another advantage to Kullback-Leibler information is that no smoothness conditions on the densities … are needed.</p>
</blockquote>
</div><div class="article-licensing box"><div class="licensing-title"><p>Math - Fisher Information</p><p><a href="https://xlindo.com/posts/c0aebc2/">https://xlindo.com/posts/c0aebc2/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>xlindo</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2019-07-06</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-05-09</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/inEnglish/">inEnglish</a><a class="link-muted mr-2" rel="tag" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/dbe6178b/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">2013年，夏天的乐队吉他手</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/12e09ac1/"><span class="level-item">SysId - Input signals in system identification</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="SOHUCS" sid="posts/c0aebc2/"></div><script charset="utf-8" src="https://changyan.sohu.com/upload/changyan.js"></script><script>window.changyan.api.config({appid: 'cyvmJmMgc',conf: 'prod_54e45394a2fad7c3e167e501900a4821'});</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/images/avatar.jpg" alt="xlindo"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">xlindo</p><p class="is-size-6 is-block">A scienthusiast.</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Sichuan, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">32</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://weibo.com/mrdo" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="http://weibo.com/mrdo"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Zhihu" href="http://www.zhihu.com/people/xlindo"><i class="fab fa-zhihu"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Mail" href="mailto:hi@xlindo.com"><i class="fas fa-envelope"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/System-Identification/"><span class="level-start"><span class="level-item">System Identification</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%B7%A1%E6%B8%B8%E8%AE%B0/"><span class="level-start"><span class="level-item">巡游记</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA/"><span class="level-start"><span class="level-item">控制理论</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E5%AD%A6%E4%B8%8E%E7%BB%9F%E8%AE%A1/"><span class="level-start"><span class="level-item">数学与统计</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">机器学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%BB%8F%E9%AA%8C%E4%B9%8B%E8%B0%88/"><span class="level-start"><span class="level-item">经验之谈</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%B7%AF/"><span class="level-start"><span class="level-item">编程之路</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-17T16:00:01.000Z">2022-04-18</time></p><p class="title"><a href="/posts/4961c61b/">How about RISC-V?</a></p><p class="categories"><a href="/categories/%E5%B7%A1%E6%B8%B8%E8%AE%B0/">巡游记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-12-04T11:26:03.000Z">2021-12-04</time></p><p class="title"><a href="/posts/ecb42a36/">性能测试-Armadillo(OpenBLAS), Eigen3, numpy, QR分解</a></p><p class="categories"><a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-11-20T16:09:28.000Z">2021-11-21</time></p><p class="title"><a href="/posts/45375/">闲</a></p><p class="categories"><a href="/categories/%E5%B7%A1%E6%B8%B8%E8%AE%B0/">巡游记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-02T16:09:28.000Z">2021-03-03</time></p><p class="title"><a href="/posts/7d4bbc2/">三年一瞥</a></p><p class="categories"><a href="/categories/%E5%B7%A1%E6%B8%B8%E8%AE%B0/">巡游记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-01-04T08:54:38.000Z">2020-01-04</time></p><p class="title"><a href="/posts/8d34e813/">DnA-LeetCode-10-正则表达式匹配-动态规划</a></p><p class="categories"><a href="/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%B7%AF/">编程之路</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/"><span class="level-start"><span class="level-item">2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/"><span class="level-start"><span class="level-item">2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/"><span class="level-start"><span class="level-item">2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/"><span class="level-start"><span class="level-item">2019</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/"><span class="level-start"><span class="level-item">2018</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/"><span class="level-start"><span class="level-item">2017</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2015/"><span class="level-start"><span class="level-item">2015</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/MATLAB/"><span class="tag">MATLAB</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TSA/"><span class="tag">TSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/about/"><span class="tag">about</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/c-cpp/"><span class="tag">c-cpp</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/inEnglish/"><span class="tag">inEnglish</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kNN/"><span class="tag">kNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/k%E8%BF%91%E9%82%BB/"><span class="tag">k近邻</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/leetcode/"><span class="tag">leetcode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/linux/"><span class="tag">linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/numpy/"><span class="tag">numpy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%87%E6%9F%A5%E6%89%8B%E5%86%8C/"><span class="tag">备查手册</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E5%85%B7/"><span class="tag">工具</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BB%BA%E6%A8%A1/"><span class="tag">建模</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"><span class="tag">性能测试</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%8E%A7%E5%88%B6/"><span class="tag">控制</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><span class="tag">数据分析</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"><span class="tag">数据结构与算法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%80%E4%BC%98%E5%8C%96/"><span class="tag">最优化</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BA%86%E5%90%97/"><span class="tag">机器学习了吗</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%94%9F%E6%B4%BB/"><span class="tag">生活 </span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A8%8B%E5%BA%8F/"><span class="tag">程序</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AC%94%E8%AE%B0/"><span class="tag">笔记</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%B3%BB%E7%BB%9F%E8%BE%A8%E8%AF%86/"><span class="tag">系统辨识</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="tag">线性代数</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BB%8F%E9%AA%8C/"><span class="tag">经验</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BC%96%E7%A8%8B/"><span class="tag">编程</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔 </span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E7%B3%BB%E7%BB%9F/"><span class="tag">非线性系统</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/favicon.ico" alt="xlindo is here" height="28"></a><p class="is-size-7"><span>&copy; 2023 xlindo</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>